{
  "hash": "cf246e7821e882dc6e40f46d625202db",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Replication of Gallstone Prediction Study (Esen et al., 2024)\"\nauthor: \"Your Name\"\ndate: \"2025-09-05\"\nformat:\n  html:\n    code-fold: true\n\nnotebook-view:\n  - notebook: penguins.ipynb\n    title: \"Data source and publication\"\n    url: https://archive.ics.uci.edu/dataset/1150/gallstone-1\n---\n\n\n\n\n\n\n\n\n## 1. Load and Prepare Data\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load your cleaned dataset\nraw_data <- read_xlsx(\"data/dataset-uci.xlsx\")  # update path\n\n# Convert target to factor with valid R variable names\nraw_data <- raw_data %>%\n  clean_names() %>%\n  mutate(gallstone_status = factor(gallstone_status, levels = c(0, 1), labels = c(\"no\", \"yes\")))\n\n# Confirm class balance\ntable(raw_data$gallstone_status)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n no yes \n161 158 \n```\n\n\n:::\n:::\n\n\n\n\n\n## 2. Split Data: Train-Test (70-30)\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\ntrain_index <- createDataPartition(raw_data$gallstone_status, p = 0.7, list = FALSE)\ntrain_data <- raw_data[train_index, ]\ntest_data <- raw_data[-train_index, ]\n```\n:::\n\n\n\n\n\n## 3. Train Multiple Models\n\n### Helper: Performance Metrics\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_metrics <- function(pred, prob, actual) {\n  conf <- confusionMatrix(pred, actual)\n  \n  # Ensure AUC is stored as a plain numeric scalar\n  auc_value <- tryCatch({\n    as.numeric(pROC::auc(pROC::roc(as.numeric(actual), as.numeric(prob))))\n  }, error = function(e) NA)\n  \n  data.frame(\n    Accuracy = conf$overall[\"Accuracy\"],\n    Precision = conf$byClass[\"Precision\"],\n    Recall = conf$byClass[\"Recall\"],\n    F1 = conf$byClass[\"F1\"],\n    AUC = auc_value\n  )\n}\n```\n:::\n\n\n\n\n\n### Logistic Regression with glmnet (Ridge)\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx_train <- model.matrix(gallstone_status ~ ., train_data)[,-1]\ny_train <- train_data$gallstone_status\nx_test <- model.matrix(gallstone_status ~ ., test_data)[,-1]\ny_test <- test_data$gallstone_status\n\ncv_fit <- cv.glmnet(x_train, y_train, alpha = 0, family = \"binomial\")\nlr_prob <- predict(cv_fit, newx = x_test, s = \"lambda.min\", type = \"response\")\nlr_pred <- factor(ifelse(lr_prob > 0.5, \"yes\", \"no\"), levels = levels(y_test))\nlr_glmnet_metrics <- get_metrics(lr_pred, lr_prob, y_test)\n```\n:::\n\n\n\n\n\n### Random Forest\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_model <- train(gallstone_status ~ ., data = train_data, method = \"rf\")\nrf_metrics <- get_metrics(predict(rf_model, test_data), predict(rf_model, test_data, type = \"prob\")[, \"yes\"], y_test)\n```\n:::\n\n\n\n\n\n### Gradient Boosting (GBM)\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngbm_model <- train(gallstone_status ~ ., data = train_data, method = \"gbm\", verbose = FALSE)\ngbm_metrics <- get_metrics(predict(gbm_model, test_data), predict(gbm_model, test_data, type = \"prob\")[, \"yes\"], y_test)\n```\n:::\n\n\n\n\n\n### Naive Bayes\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnb_model <- train(gallstone_status ~ ., data = train_data, method = \"naive_bayes\")\nnb_metrics <- get_metrics(predict(nb_model, test_data), predict(nb_model, test_data, type = \"prob\")[, \"yes\"], y_test)\n```\n:::\n\n\n\n\n\n### Support Vector Machine (RBF Kernel) with probabilities\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsvm_model <- train(\n  gallstone_status ~ ., data = train_data,\n  method = \"svmRadial\",\n  trControl = trainControl(method = \"cv\", number = 5, classProbs = TRUE, savePredictions = \"final\"),\n  preProcess = c(\"center\", \"scale\"),\n  tuneLength = 5\n)\n\nsvm_pred <- predict(svm_model, test_data)\nsvm_prob <- predict(svm_model, test_data, type = \"prob\")[, \"yes\"]\nsvm_metrics <- get_metrics(svm_pred, svm_prob, y_test)\n```\n:::\n\n\n\n\n\n### Logistic Regression \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Classic Logistic Regression\nclassic_lr_model <- glm(gallstone_status ~ ., data = train_data, family = binomial)\nclassic_lr_prob <- predict(classic_lr_model, newdata = test_data, type = \"response\")\nclassic_lr_pred <- factor(ifelse(classic_lr_prob > 0.5, \"yes\", \"no\"), levels = levels(test_data$gallstone_status))\nclassic_lr_metrics <- get_metrics(classic_lr_pred, classic_lr_prob, test_data$gallstone_status)\n```\n:::\n\n\n\n\n\n## 4. Compare Model Performance\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Combine both logistic models and others\nmodel_results <- list(\n  LR_Classic = classic_lr_metrics,\n  LR_GLMNET = lr_glmnet_metrics,\n  RF = rf_metrics,\n  GBM = gbm_metrics,\n  NB = nb_metrics,\n  SVM = svm_metrics\n)\n\n# Convert to data frame\nresults_df <- bind_rows(lapply(model_results, function(df) {\n  df[] <- lapply(df, as.numeric)\n  df\n}), .id = \"Model\")\n\ncolnames(results_df)[1] <- \"Model\"\n\n# Display sorted by AUC\nresults_df %>%\n  arrange(desc(AUC))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                  Model  Accuracy Precision    Recall        F1       AUC\nAccuracy...1  LR_GLMNET 0.8315789 0.7666667 0.9583333 0.8518519 0.8785461\nAccuracy...2        SVM 0.7789474 0.7454545 0.8541667 0.7961165 0.8577128\nAccuracy...3         RF 0.7263158 0.6833333 0.8541667 0.7592593 0.8375443\nAccuracy...4 LR_Classic 0.8000000 0.7377049 0.9375000 0.8256881 0.8280142\nAccuracy...5         NB 0.7052632 0.7500000 0.6250000 0.6818182 0.7814716\nAccuracy...6        GBM 0.7263158 0.6833333 0.8541667 0.7592593 0.7562057\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create the published study results data frame\npublished_results <- tibble::tibble(\n  Model = c(\"LR\", \"RF\", \"GB\", \"NB\", \"SVM\", \"AdaBoost\", \"XGBoost\", \"MLP\", \"DT\", \"KNN\"),\n  Accuracy = c(0.8333, 0.8542, 0.8542, 0.6250, 0.4688, 0.8229, 0.8333, 0.6667, 0.6979, 0.4896),\n  Precision = c(0.86, 0.91, 0.91, 0.61, 0.52, 0.86, 0.93, 0.76, 0.78, 0.53),\n  Recall = c(0.83, 0.81, 0.81, 0.87, 0.29, 0.81, 0.75, 0.56, 0.62, 0.44),\n  F1 = c(0.84, 0.86, 0.86, 0.71, 0.37, 0.83, 0.83, 0.64, 0.69, 0.48),\n  AUC = c(0.83, 0.85, 0.85, 0.60, 0.48, 0.82, 0.84, 0.67, 0.70, 0.49)\n)\n\n\n# Render styled HTML table\npublished_results %>%\n  kable(format = \"html\", digits = 2, caption = \"Published Model Performance (Esen et al., 2024)\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = FALSE)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover table-condensed table-responsive\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Published Model Performance (Esen et al., 2024)</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Model </th>\n   <th style=\"text-align:right;\"> Accuracy </th>\n   <th style=\"text-align:right;\"> Precision </th>\n   <th style=\"text-align:right;\"> Recall </th>\n   <th style=\"text-align:right;\"> F1 </th>\n   <th style=\"text-align:right;\"> AUC </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> LR </td>\n   <td style=\"text-align:right;\"> 0.83 </td>\n   <td style=\"text-align:right;\"> 0.86 </td>\n   <td style=\"text-align:right;\"> 0.83 </td>\n   <td style=\"text-align:right;\"> 0.84 </td>\n   <td style=\"text-align:right;\"> 0.83 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> RF </td>\n   <td style=\"text-align:right;\"> 0.85 </td>\n   <td style=\"text-align:right;\"> 0.91 </td>\n   <td style=\"text-align:right;\"> 0.81 </td>\n   <td style=\"text-align:right;\"> 0.86 </td>\n   <td style=\"text-align:right;\"> 0.85 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> GB </td>\n   <td style=\"text-align:right;\"> 0.85 </td>\n   <td style=\"text-align:right;\"> 0.91 </td>\n   <td style=\"text-align:right;\"> 0.81 </td>\n   <td style=\"text-align:right;\"> 0.86 </td>\n   <td style=\"text-align:right;\"> 0.85 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> NB </td>\n   <td style=\"text-align:right;\"> 0.62 </td>\n   <td style=\"text-align:right;\"> 0.61 </td>\n   <td style=\"text-align:right;\"> 0.87 </td>\n   <td style=\"text-align:right;\"> 0.71 </td>\n   <td style=\"text-align:right;\"> 0.60 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> SVM </td>\n   <td style=\"text-align:right;\"> 0.47 </td>\n   <td style=\"text-align:right;\"> 0.52 </td>\n   <td style=\"text-align:right;\"> 0.29 </td>\n   <td style=\"text-align:right;\"> 0.37 </td>\n   <td style=\"text-align:right;\"> 0.48 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> AdaBoost </td>\n   <td style=\"text-align:right;\"> 0.82 </td>\n   <td style=\"text-align:right;\"> 0.86 </td>\n   <td style=\"text-align:right;\"> 0.81 </td>\n   <td style=\"text-align:right;\"> 0.83 </td>\n   <td style=\"text-align:right;\"> 0.82 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> XGBoost </td>\n   <td style=\"text-align:right;\"> 0.83 </td>\n   <td style=\"text-align:right;\"> 0.93 </td>\n   <td style=\"text-align:right;\"> 0.75 </td>\n   <td style=\"text-align:right;\"> 0.83 </td>\n   <td style=\"text-align:right;\"> 0.84 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> MLP </td>\n   <td style=\"text-align:right;\"> 0.67 </td>\n   <td style=\"text-align:right;\"> 0.76 </td>\n   <td style=\"text-align:right;\"> 0.56 </td>\n   <td style=\"text-align:right;\"> 0.64 </td>\n   <td style=\"text-align:right;\"> 0.67 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> DT </td>\n   <td style=\"text-align:right;\"> 0.70 </td>\n   <td style=\"text-align:right;\"> 0.78 </td>\n   <td style=\"text-align:right;\"> 0.62 </td>\n   <td style=\"text-align:right;\"> 0.69 </td>\n   <td style=\"text-align:right;\"> 0.70 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> KNN </td>\n   <td style=\"text-align:right;\"> 0.49 </td>\n   <td style=\"text-align:right;\"> 0.53 </td>\n   <td style=\"text-align:right;\"> 0.44 </td>\n   <td style=\"text-align:right;\"> 0.48 </td>\n   <td style=\"text-align:right;\"> 0.49 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load required package\n\n\n# Create the table\npublished_results <- tibble::tibble(\n  Model = c(\"LR\", \"RF\", \"GB\", \"NB\", \"SVM\"),\n  Accuracy = c(0.83, 0.85, 0.85, 0.63, 0.47),\n  Precision = c(0.86, 0.91, 0.91, 0.61, 0.52),\n  Recall = c(0.83, 0.81, 0.81, 0.87, 0.29),\n  `F1 Score` = c(0.84, 0.86, 0.86, 0.71, 0.37),\n  AUC = c(0.83, 0.85, 0.85, 0.60, 0.48)\n)\n\n# Display a nicely formatted HTML table\npublished_results %>%\n  arrange(desc(AUC)) %>% \n  kable(format = \"html\", digits = 2, caption = \"Published Model Performance (Esen et al., 2024)\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = FALSE)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover table-condensed table-responsive\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Published Model Performance (Esen et al., 2024)</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Model </th>\n   <th style=\"text-align:right;\"> Accuracy </th>\n   <th style=\"text-align:right;\"> Precision </th>\n   <th style=\"text-align:right;\"> Recall </th>\n   <th style=\"text-align:right;\"> F1 Score </th>\n   <th style=\"text-align:right;\"> AUC </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> RF </td>\n   <td style=\"text-align:right;\"> 0.85 </td>\n   <td style=\"text-align:right;\"> 0.91 </td>\n   <td style=\"text-align:right;\"> 0.81 </td>\n   <td style=\"text-align:right;\"> 0.86 </td>\n   <td style=\"text-align:right;\"> 0.85 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> GB </td>\n   <td style=\"text-align:right;\"> 0.85 </td>\n   <td style=\"text-align:right;\"> 0.91 </td>\n   <td style=\"text-align:right;\"> 0.81 </td>\n   <td style=\"text-align:right;\"> 0.86 </td>\n   <td style=\"text-align:right;\"> 0.85 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> LR </td>\n   <td style=\"text-align:right;\"> 0.83 </td>\n   <td style=\"text-align:right;\"> 0.86 </td>\n   <td style=\"text-align:right;\"> 0.83 </td>\n   <td style=\"text-align:right;\"> 0.84 </td>\n   <td style=\"text-align:right;\"> 0.83 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> NB </td>\n   <td style=\"text-align:right;\"> 0.63 </td>\n   <td style=\"text-align:right;\"> 0.61 </td>\n   <td style=\"text-align:right;\"> 0.87 </td>\n   <td style=\"text-align:right;\"> 0.71 </td>\n   <td style=\"text-align:right;\"> 0.60 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> SVM </td>\n   <td style=\"text-align:right;\"> 0.47 </td>\n   <td style=\"text-align:right;\"> 0.52 </td>\n   <td style=\"text-align:right;\"> 0.29 </td>\n   <td style=\"text-align:right;\"> 0.37 </td>\n   <td style=\"text-align:right;\"> 0.48 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n\n```{.r .cell-code}\n# Display a styled HTML table of your replication results\nrownames(results_df) <- NULL\nresults_df %>%\n  arrange(desc(AUC)) %>% \n  kable(format = \"html\", digits = 2, caption = \"Replicated Model Performance\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = FALSE)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover table-condensed table-responsive\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Replicated Model Performance</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Model </th>\n   <th style=\"text-align:right;\"> Accuracy </th>\n   <th style=\"text-align:right;\"> Precision </th>\n   <th style=\"text-align:right;\"> Recall </th>\n   <th style=\"text-align:right;\"> F1 </th>\n   <th style=\"text-align:right;\"> AUC </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> LR_GLMNET </td>\n   <td style=\"text-align:right;\"> 0.83 </td>\n   <td style=\"text-align:right;\"> 0.77 </td>\n   <td style=\"text-align:right;\"> 0.96 </td>\n   <td style=\"text-align:right;\"> 0.85 </td>\n   <td style=\"text-align:right;\"> 0.88 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> SVM </td>\n   <td style=\"text-align:right;\"> 0.78 </td>\n   <td style=\"text-align:right;\"> 0.75 </td>\n   <td style=\"text-align:right;\"> 0.85 </td>\n   <td style=\"text-align:right;\"> 0.80 </td>\n   <td style=\"text-align:right;\"> 0.86 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> RF </td>\n   <td style=\"text-align:right;\"> 0.73 </td>\n   <td style=\"text-align:right;\"> 0.68 </td>\n   <td style=\"text-align:right;\"> 0.85 </td>\n   <td style=\"text-align:right;\"> 0.76 </td>\n   <td style=\"text-align:right;\"> 0.84 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> LR_Classic </td>\n   <td style=\"text-align:right;\"> 0.80 </td>\n   <td style=\"text-align:right;\"> 0.74 </td>\n   <td style=\"text-align:right;\"> 0.94 </td>\n   <td style=\"text-align:right;\"> 0.83 </td>\n   <td style=\"text-align:right;\"> 0.83 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> NB </td>\n   <td style=\"text-align:right;\"> 0.71 </td>\n   <td style=\"text-align:right;\"> 0.75 </td>\n   <td style=\"text-align:right;\"> 0.62 </td>\n   <td style=\"text-align:right;\"> 0.68 </td>\n   <td style=\"text-align:right;\"> 0.78 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> GBM </td>\n   <td style=\"text-align:right;\"> 0.73 </td>\n   <td style=\"text-align:right;\"> 0.68 </td>\n   <td style=\"text-align:right;\"> 0.85 </td>\n   <td style=\"text-align:right;\"> 0.76 </td>\n   <td style=\"text-align:right;\"> 0.76 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n\n\n\n\n## 5. Feature Importance from GBM\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get variable importance\ngbm_varimp <- varImp(gbm_model)\n\n# Update rownames with descriptive labels (if found)\nrownames(gbm_varimp$importance) <- variable_labels[rownames(gbm_varimp$importance)]\n\nplot(gbm_varimp, top = 15, main = \"Top Features - Gradient Boosting\")\n```\n\n::: {.cell-output-display}\n![](replication_files/figure-html/importance-1.png){width=672}\n:::\n:::\n\n\n\n\n\n## ✅ Conclusion\n\n- Factor levels are now recoded to valid names (`no`, `yes`) to enable class probability predictions.\n- SVM and all other models now support AUC and probability-based evaluation.\n- Gradient Boosting and Random Forest remain strong performers for gallstone prediction.\n",
    "supporting": [
      "replication_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
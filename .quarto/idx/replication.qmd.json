{"title":"Replication of Gallstone Prediction Study (Esen et al., 2024)","markdown":{"yaml":{"title":"Replication of Gallstone Prediction Study (Esen et al., 2024)","author":"Anna Calderon","date":"`r Sys.Date()`","format":{"html":{"code-fold":true}},"notebook-view":[{"notebook":"penguins.ipynb","title":"Data source and publication","url":"https://archive.ics.uci.edu/dataset/1150/gallstone-1"}]},"headingText":"1. Load and Prepare Data","containsRefs":false,"markdown":"\n\n\n\n\n\n```{r set-up, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)\nlibrary(tidyverse)\nlibrary(caret)\nlibrary(janitor)\nlibrary(corrplot)\nlibrary(e1071)\nlibrary(randomForest)\nlibrary(glmnet)\nlibrary(xgboost)\nlibrary(naivebayes)\nlibrary(pROC)\nlibrary(GGally)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(gbm)\nlibrary(readxl)\n```\n\n\n\n```{r load-data}\n# Load your cleaned dataset\nraw_data <- read_xlsx(\"data/dataset-uci.xlsx\")  # update path\n\n# Convert target to factor with valid R variable names\nraw_data <- raw_data %>%\n  clean_names() %>%\n  mutate(gallstone_status = factor(gallstone_status, levels = c(0, 1), labels = c(\"no\", \"yes\")))\n\n# Confirm class balance\ntable(raw_data$gallstone_status)\n```\n\n## 2. Split Data: Train-Test (70-30)\n\n```{r split-data}\nset.seed(123)\ntrain_index <- createDataPartition(raw_data$gallstone_status, p = 0.7, list = FALSE)\ntrain_data <- raw_data[train_index, ]\ntest_data <- raw_data[-train_index, ]\n```\n\n## 3. Train Multiple Models\n\n### Helper: Performance Metrics\n\n```{r metric-function}\nget_metrics <- function(pred, prob, actual) {\n  conf <- confusionMatrix(pred, actual)\n  \n  # Ensure AUC is stored as a plain numeric scalar\n  auc_value <- tryCatch({\n    as.numeric(pROC::auc(pROC::roc(as.numeric(actual), as.numeric(prob))))\n  }, error = function(e) NA)\n  \n  data.frame(\n    Accuracy = conf$overall[\"Accuracy\"],\n    Precision = conf$byClass[\"Precision\"],\n    Recall = conf$byClass[\"Recall\"],\n    F1 = conf$byClass[\"F1\"],\n    AUC = auc_value\n  )\n}\n```\n\n### Logistic Regression with glmnet (Ridge)\n\n```{r glmnet}\nx_train <- model.matrix(gallstone_status ~ ., train_data)[,-1]\ny_train <- train_data$gallstone_status\nx_test <- model.matrix(gallstone_status ~ ., test_data)[,-1]\ny_test <- test_data$gallstone_status\n\ncv_fit <- cv.glmnet(x_train, y_train, alpha = 0, family = \"binomial\")\nlr_prob <- predict(cv_fit, newx = x_test, s = \"lambda.min\", type = \"response\")\nlr_pred <- factor(ifelse(lr_prob > 0.5, \"yes\", \"no\"), levels = levels(y_test))\nlr_glmnet_metrics <- get_metrics(lr_pred, lr_prob, y_test)\n```\n\n### Random Forest\n\n```{r rf}\nrf_model <- train(gallstone_status ~ ., data = train_data, method = \"rf\")\nrf_metrics <- get_metrics(predict(rf_model, test_data), predict(rf_model, test_data, type = \"prob\")[, \"yes\"], y_test)\n```\n\n### Gradient Boosting (GBM)\n\n```{r gbm}\ngbm_model <- train(gallstone_status ~ ., data = train_data, method = \"gbm\", verbose = FALSE)\ngbm_metrics <- get_metrics(predict(gbm_model, test_data), predict(gbm_model, test_data, type = \"prob\")[, \"yes\"], y_test)\n```\n\n### Naive Bayes\n\n```{r nb}\nnb_model <- train(gallstone_status ~ ., data = train_data, method = \"naive_bayes\")\nnb_metrics <- get_metrics(predict(nb_model, test_data), predict(nb_model, test_data, type = \"prob\")[, \"yes\"], y_test)\n```\n\n### Support Vector Machine (RBF Kernel) with probabilities\n\n```{r svm}\nsvm_model <- train(\n  gallstone_status ~ ., data = train_data,\n  method = \"svmRadial\",\n  trControl = trainControl(method = \"cv\", number = 5, classProbs = TRUE, savePredictions = \"final\"),\n  preProcess = c(\"center\", \"scale\"),\n  tuneLength = 5\n)\n\nsvm_pred <- predict(svm_model, test_data)\nsvm_prob <- predict(svm_model, test_data, type = \"prob\")[, \"yes\"]\nsvm_metrics <- get_metrics(svm_pred, svm_prob, y_test)\n```\n\n### Logistic Regression \n\n```{r}\n# Classic Logistic Regression\nclassic_lr_model <- glm(gallstone_status ~ ., data = train_data, family = binomial)\nclassic_lr_prob <- predict(classic_lr_model, newdata = test_data, type = \"response\")\nclassic_lr_pred <- factor(ifelse(classic_lr_prob > 0.5, \"yes\", \"no\"), levels = levels(test_data$gallstone_status))\nclassic_lr_metrics <- get_metrics(classic_lr_pred, classic_lr_prob, test_data$gallstone_status)\n\n\n\n```\n\n## 4. Compare Model Performance\n\n```{r compare}\n\n# Combine both logistic models and others\nmodel_results <- list(\n  LR_Classic = classic_lr_metrics,\n  LR_GLMNET = lr_glmnet_metrics,\n  RF = rf_metrics,\n  GBM = gbm_metrics,\n  NB = nb_metrics,\n  SVM = svm_metrics\n)\n\n# Convert to data frame\nresults_df <- bind_rows(lapply(model_results, function(df) {\n  df[] <- lapply(df, as.numeric)\n  df\n}), .id = \"Model\")\n\ncolnames(results_df)[1] <- \"Model\"\n\n# Display sorted by AUC\nresults_df %>%\n  arrange(desc(AUC))\n\n\n```\n\n```{r}\n# Create the published study results data frame\npublished_results <- tibble::tibble(\n  Model = c(\"LR\", \"RF\", \"GB\", \"NB\", \"SVM\", \"AdaBoost\", \"XGBoost\", \"MLP\", \"DT\", \"KNN\"),\n  Accuracy = c(0.8333, 0.8542, 0.8542, 0.6250, 0.4688, 0.8229, 0.8333, 0.6667, 0.6979, 0.4896),\n  Precision = c(0.86, 0.91, 0.91, 0.61, 0.52, 0.86, 0.93, 0.76, 0.78, 0.53),\n  Recall = c(0.83, 0.81, 0.81, 0.87, 0.29, 0.81, 0.75, 0.56, 0.62, 0.44),\n  F1 = c(0.84, 0.86, 0.86, 0.71, 0.37, 0.83, 0.83, 0.64, 0.69, 0.48),\n  AUC = c(0.83, 0.85, 0.85, 0.60, 0.48, 0.82, 0.84, 0.67, 0.70, 0.49)\n)\n\n\n# Render styled HTML table\npublished_results %>%\n  kable(format = \"html\", digits = 2, caption = \"Published Model Performance (Esen et al., 2024)\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = FALSE)\n\n\n```\n\n\n```{r}\n# Load required package\n\n\n# Create the table\npublished_results <- tibble::tibble(\n  Model = c(\"LR\", \"RF\", \"GB\", \"NB\", \"SVM\"),\n  Accuracy = c(0.83, 0.85, 0.85, 0.63, 0.47),\n  Precision = c(0.86, 0.91, 0.91, 0.61, 0.52),\n  Recall = c(0.83, 0.81, 0.81, 0.87, 0.29),\n  `F1 Score` = c(0.84, 0.86, 0.86, 0.71, 0.37),\n  AUC = c(0.83, 0.85, 0.85, 0.60, 0.48)\n)\n\n# Display a nicely formatted HTML table\npublished_results %>%\n  arrange(desc(AUC)) %>% \n  kable(format = \"html\", digits = 2, caption = \"Published Model Performance (Esen et al., 2024)\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = FALSE)\n\n\n# Display a styled HTML table of your replication results\nrownames(results_df) <- NULL\nresults_df %>%\n  arrange(desc(AUC)) %>% \n  kable(format = \"html\", digits = 2, caption = \"Replicated Model Performance\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = FALSE)\n```\n\n```{r}\n#| include: false\n# Your variable name mapping as a named vector\n# Variable name mapping (as before)\nvariable_labels <- c(\n  body_mass_index_bmi = \"Body Mass Index\",\n  total_body_water_tbw = \"Total Body Water\",\n  extracellular_water_ecw = \"Extracellular Water\",\n  intracellular_water_icw = \"Intracellular Water\",\n  extracellular_fluid_total_body_water_ecf_tbw = \"Extracellular Fluid to Total Body Water\",\n  total_body_fat_ratio_tbfr_percent = \"Total Body Fat Ratio\",\n  lean_mass_lm_percent = \"Lean Mass\",\n  body_protein_content_protein_percent = \"Body Protein Content\",\n  visceral_fat_rating_vfr = \"Visceral Fat Rating\",\n  bone_mass_bm = \"Bone Mass\",\n  gallstone_status = \"Gallstone Status\",\n  age = \"Age\",\n  gender = \"Gender\",\n  comorbidity = \"Comorbidity\",\n  coronary_artery_disease_cad = \"Coronary Artery Disease\",\n  hypothyroidism = \"Hypothyroidism\",\n  hyperlipidemia = \"Hyperlipidemia\",\n  diabetes_mellitus_dm = \"Diabetes Mellitus\",\n  height = \"Height\",\n  weight = \"Weight\",\n  muscle_mass_mm = \"Muscle Mass\",\n  obesity_percent = \"Obesity\",\n  total_fat_content_tfc = \"Total Fat Content\",\n  visceral_fat_area_vfa = \"Visceral Fat Area\",\n  visceral_muscle_area_vma_kg = \"Visceral Muscle Area\",\n  hepatic_fat_accumulation_hfa = \"Hepatic Fat Accumulation\",\n  glucose = \"Glucose\",\n  total_cholesterol_tc = \"Total Cholesterol\",\n  low_density_lipoprotein_ldl = \"Low Density Lipoprotein\",\n  high_density_lipoprotein_hdl = \"High Density Lipoprotein\",\n  triglyceride = \"Triglyceride\",\n  aspartat_aminotransferaz_ast = \"Aspartat Aminotransferaz\",\n  alanin_aminotransferaz_alt = \"Alanin Aminotransferaz\",\n  alkaline_phosphatase_alp = \"Alkaline Phosphatase\",\n  creatinine = \"Creatinine\",\n  glomerular_filtration_rate_gfr = \"Glomerular Filtration Rate\",\n  c_reactive_protein_crp = \"C-Reactive Protein\",\n  hemoglobin_hgb = \"Hemoglobin\",\n  vitamin_d = \"Vitamin D\"\n)\n```\n\n## 5. Feature Importance from GBM\n\n```{r importance}\n\n\n# Get variable importance\ngbm_varimp <- varImp(gbm_model)\n\n# Update rownames with descriptive labels (if found)\nrownames(gbm_varimp$importance) <- variable_labels[rownames(gbm_varimp$importance)]\n\nplot(gbm_varimp, top = 15, main = \"Top Features - Gradient Boosting\")\n```\n\n## Conclusion\n\n- Factor levels are now recoded to valid names (`no`, `yes`) to enable class probability predictions.\n- SVM and all other models now support AUC and probability-based evaluation.\n- Gradient Boosting and Random Forest remain strong performers for gallstone prediction.\n","srcMarkdownNoYaml":"\n\n\n\n\n\n```{r set-up, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)\nlibrary(tidyverse)\nlibrary(caret)\nlibrary(janitor)\nlibrary(corrplot)\nlibrary(e1071)\nlibrary(randomForest)\nlibrary(glmnet)\nlibrary(xgboost)\nlibrary(naivebayes)\nlibrary(pROC)\nlibrary(GGally)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(gbm)\nlibrary(readxl)\n```\n\n\n## 1. Load and Prepare Data\n\n```{r load-data}\n# Load your cleaned dataset\nraw_data <- read_xlsx(\"data/dataset-uci.xlsx\")  # update path\n\n# Convert target to factor with valid R variable names\nraw_data <- raw_data %>%\n  clean_names() %>%\n  mutate(gallstone_status = factor(gallstone_status, levels = c(0, 1), labels = c(\"no\", \"yes\")))\n\n# Confirm class balance\ntable(raw_data$gallstone_status)\n```\n\n## 2. Split Data: Train-Test (70-30)\n\n```{r split-data}\nset.seed(123)\ntrain_index <- createDataPartition(raw_data$gallstone_status, p = 0.7, list = FALSE)\ntrain_data <- raw_data[train_index, ]\ntest_data <- raw_data[-train_index, ]\n```\n\n## 3. Train Multiple Models\n\n### Helper: Performance Metrics\n\n```{r metric-function}\nget_metrics <- function(pred, prob, actual) {\n  conf <- confusionMatrix(pred, actual)\n  \n  # Ensure AUC is stored as a plain numeric scalar\n  auc_value <- tryCatch({\n    as.numeric(pROC::auc(pROC::roc(as.numeric(actual), as.numeric(prob))))\n  }, error = function(e) NA)\n  \n  data.frame(\n    Accuracy = conf$overall[\"Accuracy\"],\n    Precision = conf$byClass[\"Precision\"],\n    Recall = conf$byClass[\"Recall\"],\n    F1 = conf$byClass[\"F1\"],\n    AUC = auc_value\n  )\n}\n```\n\n### Logistic Regression with glmnet (Ridge)\n\n```{r glmnet}\nx_train <- model.matrix(gallstone_status ~ ., train_data)[,-1]\ny_train <- train_data$gallstone_status\nx_test <- model.matrix(gallstone_status ~ ., test_data)[,-1]\ny_test <- test_data$gallstone_status\n\ncv_fit <- cv.glmnet(x_train, y_train, alpha = 0, family = \"binomial\")\nlr_prob <- predict(cv_fit, newx = x_test, s = \"lambda.min\", type = \"response\")\nlr_pred <- factor(ifelse(lr_prob > 0.5, \"yes\", \"no\"), levels = levels(y_test))\nlr_glmnet_metrics <- get_metrics(lr_pred, lr_prob, y_test)\n```\n\n### Random Forest\n\n```{r rf}\nrf_model <- train(gallstone_status ~ ., data = train_data, method = \"rf\")\nrf_metrics <- get_metrics(predict(rf_model, test_data), predict(rf_model, test_data, type = \"prob\")[, \"yes\"], y_test)\n```\n\n### Gradient Boosting (GBM)\n\n```{r gbm}\ngbm_model <- train(gallstone_status ~ ., data = train_data, method = \"gbm\", verbose = FALSE)\ngbm_metrics <- get_metrics(predict(gbm_model, test_data), predict(gbm_model, test_data, type = \"prob\")[, \"yes\"], y_test)\n```\n\n### Naive Bayes\n\n```{r nb}\nnb_model <- train(gallstone_status ~ ., data = train_data, method = \"naive_bayes\")\nnb_metrics <- get_metrics(predict(nb_model, test_data), predict(nb_model, test_data, type = \"prob\")[, \"yes\"], y_test)\n```\n\n### Support Vector Machine (RBF Kernel) with probabilities\n\n```{r svm}\nsvm_model <- train(\n  gallstone_status ~ ., data = train_data,\n  method = \"svmRadial\",\n  trControl = trainControl(method = \"cv\", number = 5, classProbs = TRUE, savePredictions = \"final\"),\n  preProcess = c(\"center\", \"scale\"),\n  tuneLength = 5\n)\n\nsvm_pred <- predict(svm_model, test_data)\nsvm_prob <- predict(svm_model, test_data, type = \"prob\")[, \"yes\"]\nsvm_metrics <- get_metrics(svm_pred, svm_prob, y_test)\n```\n\n### Logistic Regression \n\n```{r}\n# Classic Logistic Regression\nclassic_lr_model <- glm(gallstone_status ~ ., data = train_data, family = binomial)\nclassic_lr_prob <- predict(classic_lr_model, newdata = test_data, type = \"response\")\nclassic_lr_pred <- factor(ifelse(classic_lr_prob > 0.5, \"yes\", \"no\"), levels = levels(test_data$gallstone_status))\nclassic_lr_metrics <- get_metrics(classic_lr_pred, classic_lr_prob, test_data$gallstone_status)\n\n\n\n```\n\n## 4. Compare Model Performance\n\n```{r compare}\n\n# Combine both logistic models and others\nmodel_results <- list(\n  LR_Classic = classic_lr_metrics,\n  LR_GLMNET = lr_glmnet_metrics,\n  RF = rf_metrics,\n  GBM = gbm_metrics,\n  NB = nb_metrics,\n  SVM = svm_metrics\n)\n\n# Convert to data frame\nresults_df <- bind_rows(lapply(model_results, function(df) {\n  df[] <- lapply(df, as.numeric)\n  df\n}), .id = \"Model\")\n\ncolnames(results_df)[1] <- \"Model\"\n\n# Display sorted by AUC\nresults_df %>%\n  arrange(desc(AUC))\n\n\n```\n\n```{r}\n# Create the published study results data frame\npublished_results <- tibble::tibble(\n  Model = c(\"LR\", \"RF\", \"GB\", \"NB\", \"SVM\", \"AdaBoost\", \"XGBoost\", \"MLP\", \"DT\", \"KNN\"),\n  Accuracy = c(0.8333, 0.8542, 0.8542, 0.6250, 0.4688, 0.8229, 0.8333, 0.6667, 0.6979, 0.4896),\n  Precision = c(0.86, 0.91, 0.91, 0.61, 0.52, 0.86, 0.93, 0.76, 0.78, 0.53),\n  Recall = c(0.83, 0.81, 0.81, 0.87, 0.29, 0.81, 0.75, 0.56, 0.62, 0.44),\n  F1 = c(0.84, 0.86, 0.86, 0.71, 0.37, 0.83, 0.83, 0.64, 0.69, 0.48),\n  AUC = c(0.83, 0.85, 0.85, 0.60, 0.48, 0.82, 0.84, 0.67, 0.70, 0.49)\n)\n\n\n# Render styled HTML table\npublished_results %>%\n  kable(format = \"html\", digits = 2, caption = \"Published Model Performance (Esen et al., 2024)\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = FALSE)\n\n\n```\n\n\n```{r}\n# Load required package\n\n\n# Create the table\npublished_results <- tibble::tibble(\n  Model = c(\"LR\", \"RF\", \"GB\", \"NB\", \"SVM\"),\n  Accuracy = c(0.83, 0.85, 0.85, 0.63, 0.47),\n  Precision = c(0.86, 0.91, 0.91, 0.61, 0.52),\n  Recall = c(0.83, 0.81, 0.81, 0.87, 0.29),\n  `F1 Score` = c(0.84, 0.86, 0.86, 0.71, 0.37),\n  AUC = c(0.83, 0.85, 0.85, 0.60, 0.48)\n)\n\n# Display a nicely formatted HTML table\npublished_results %>%\n  arrange(desc(AUC)) %>% \n  kable(format = \"html\", digits = 2, caption = \"Published Model Performance (Esen et al., 2024)\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = FALSE)\n\n\n# Display a styled HTML table of your replication results\nrownames(results_df) <- NULL\nresults_df %>%\n  arrange(desc(AUC)) %>% \n  kable(format = \"html\", digits = 2, caption = \"Replicated Model Performance\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = FALSE)\n```\n\n```{r}\n#| include: false\n# Your variable name mapping as a named vector\n# Variable name mapping (as before)\nvariable_labels <- c(\n  body_mass_index_bmi = \"Body Mass Index\",\n  total_body_water_tbw = \"Total Body Water\",\n  extracellular_water_ecw = \"Extracellular Water\",\n  intracellular_water_icw = \"Intracellular Water\",\n  extracellular_fluid_total_body_water_ecf_tbw = \"Extracellular Fluid to Total Body Water\",\n  total_body_fat_ratio_tbfr_percent = \"Total Body Fat Ratio\",\n  lean_mass_lm_percent = \"Lean Mass\",\n  body_protein_content_protein_percent = \"Body Protein Content\",\n  visceral_fat_rating_vfr = \"Visceral Fat Rating\",\n  bone_mass_bm = \"Bone Mass\",\n  gallstone_status = \"Gallstone Status\",\n  age = \"Age\",\n  gender = \"Gender\",\n  comorbidity = \"Comorbidity\",\n  coronary_artery_disease_cad = \"Coronary Artery Disease\",\n  hypothyroidism = \"Hypothyroidism\",\n  hyperlipidemia = \"Hyperlipidemia\",\n  diabetes_mellitus_dm = \"Diabetes Mellitus\",\n  height = \"Height\",\n  weight = \"Weight\",\n  muscle_mass_mm = \"Muscle Mass\",\n  obesity_percent = \"Obesity\",\n  total_fat_content_tfc = \"Total Fat Content\",\n  visceral_fat_area_vfa = \"Visceral Fat Area\",\n  visceral_muscle_area_vma_kg = \"Visceral Muscle Area\",\n  hepatic_fat_accumulation_hfa = \"Hepatic Fat Accumulation\",\n  glucose = \"Glucose\",\n  total_cholesterol_tc = \"Total Cholesterol\",\n  low_density_lipoprotein_ldl = \"Low Density Lipoprotein\",\n  high_density_lipoprotein_hdl = \"High Density Lipoprotein\",\n  triglyceride = \"Triglyceride\",\n  aspartat_aminotransferaz_ast = \"Aspartat Aminotransferaz\",\n  alanin_aminotransferaz_alt = \"Alanin Aminotransferaz\",\n  alkaline_phosphatase_alp = \"Alkaline Phosphatase\",\n  creatinine = \"Creatinine\",\n  glomerular_filtration_rate_gfr = \"Glomerular Filtration Rate\",\n  c_reactive_protein_crp = \"C-Reactive Protein\",\n  hemoglobin_hgb = \"Hemoglobin\",\n  vitamin_d = \"Vitamin D\"\n)\n```\n\n## 5. Feature Importance from GBM\n\n```{r importance}\n\n\n# Get variable importance\ngbm_varimp <- varImp(gbm_model)\n\n# Update rownames with descriptive labels (if found)\nrownames(gbm_varimp$importance) <- variable_labels[rownames(gbm_varimp$importance)]\n\nplot(gbm_varimp, top = 15, main = \"Top Features - Gradient Boosting\")\n```\n\n## Conclusion\n\n- Factor levels are now recoded to valid names (`no`, `yes`) to enable class probability predictions.\n- SVM and all other models now support AUC and probability-based evaluation.\n- Gradient Boosting and Random Forest remain strong performers for gallstone prediction.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"notebook-view":[{"notebook":"penguins.ipynb","title":"Data source and publication","url":"https://archive.ics.uci.edu/dataset/1150/gallstone-1"}]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"output-file":"replication.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.32","theme":["cosmo","brand"],"title":"Replication of Gallstone Prediction Study (Esen et al., 2024)","author":"Anna Calderon","date":"`r Sys.Date()`"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}